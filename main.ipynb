{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "### Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "### HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "### Warnings\n",
    "import warnings\n",
    "### Text Preprocessing and Natural Language Processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "      <td>1.002267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.625906e+05</td>\n",
       "      <td>2.101624e+00</td>\n",
       "      <td>2.139664e+01</td>\n",
       "      <td>7.421149e+05</td>\n",
       "      <td>5.059751e+01</td>\n",
       "      <td>2.924065e+05</td>\n",
       "      <td>1.349021e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.549163e+05</td>\n",
       "      <td>3.110503e+00</td>\n",
       "      <td>3.391106e+02</td>\n",
       "      <td>1.803934e+07</td>\n",
       "      <td>6.229370e+01</td>\n",
       "      <td>5.134357e+06</td>\n",
       "      <td>8.071102e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.200000e+01</td>\n",
       "      <td>-2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.705740e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.643460e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.721775e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.140000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.254286e+06</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.449500e+04</td>\n",
       "      <td>3.000000e+09</td>\n",
       "      <td>1.440000e+04</td>\n",
       "      <td>9.000000e+08</td>\n",
       "      <td>2.994357e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  vote_average  ...        budget    popularity\n",
       "count  1.002267e+06  1.002267e+06  ...  1.002267e+06  1.002267e+06\n",
       "mean   6.625906e+05  2.101624e+00  ...  2.924065e+05  1.349021e+00\n",
       "std    3.549163e+05  3.110503e+00  ...  5.134357e+06  8.071102e+00\n",
       "min    2.000000e+00  0.000000e+00  ...  0.000000e+00  0.000000e+00\n",
       "25%    3.705740e+05  0.000000e+00  ...  0.000000e+00  6.000000e-01\n",
       "50%    6.643460e+05  0.000000e+00  ...  0.000000e+00  6.000000e-01\n",
       "75%    9.721775e+05  5.000000e+00  ...  0.000000e+00  9.140000e-01\n",
       "max    1.254286e+06  1.000000e+01  ...  9.000000e+08  2.994357e+03\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_df = pd.read_csv('TMDB_movie_dataset_v11.csv') #tmdb dataset we will be working with\n",
    "tmdb_df\n",
    "tmdb_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>status</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>budget</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>year</th>\n",
       "      <th>title_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Released</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>825532764</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "      <td>/8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg</td>\n",
       "      <td>160000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/inception</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>en</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>/oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Action, Science Fiction, Adventure</td>\n",
       "      <td>Legendary Pictures, Syncopy, Warner Bros. Pict...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, French, Japanese, Swahili</td>\n",
       "      <td>2010</td>\n",
       "      <td>Inception (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Released</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>701729206</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "      <td>/pbrkL804c8yAv3zBZR4QPEafpAR.jpg</td>\n",
       "      <td>165000000</td>\n",
       "      <td>http://www.interstellarmovie.net/</td>\n",
       "      <td>tt0816692</td>\n",
       "      <td>en</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>/gEU2QniE6E77NI6lCU6MxlNBvIx.jpg</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Adventure, Drama, Science Fiction</td>\n",
       "      <td>Legendary Pictures, Syncopy, Lynda Obst Produc...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>2014</td>\n",
       "      <td>Interstellar (2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>Released</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>1004558444</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg</td>\n",
       "      <td>185000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/dark-knight/</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Batman raises the stakes in his war on crime. ...</td>\n",
       "      <td>130.643</td>\n",
       "      <td>/qJ2tW6WMUDux911r6m7haRef0WH.jpg</td>\n",
       "      <td>Welcome to a world without rules.</td>\n",
       "      <td>Drama, Action, Crime, Thriller</td>\n",
       "      <td>DC Comics, Legendary Pictures, Syncopy, Isobel...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Dark Knight (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>Released</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>2923706026</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>237000000</td>\n",
       "      <td>https://www.avatar.com/movies/avatar</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>79.932</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>Dune Entertainment, Lightstorm Entertainment, ...</td>\n",
       "      <td>United States of America, United Kingdom</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>2009</td>\n",
       "      <td>Avatar (2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>Released</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg</td>\n",
       "      <td>220000000</td>\n",
       "      <td>https://www.marvel.com/movies/the-avengers</td>\n",
       "      <td>tt0848228</td>\n",
       "      <td>en</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>98.082</td>\n",
       "      <td>/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>Science Fiction, Action, Adventure</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English, Hindi, Russian</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Avengers (2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002262</th>\n",
       "      <td>664753</td>\n",
       "      <td>Dead Kennedys: Live in Vienna</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>Dead Kennedys: Live in Vienna</td>\n",
       "      <td>Dead Kennedys filmed live at Arena Wien in Vie...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/nQ9RmZhdYhv8QHCoHgNBfyqewB6.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "      <td>Welder</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>1982</td>\n",
       "      <td>Dead Kennedys: Live in Vienna (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002263</th>\n",
       "      <td>664754</td>\n",
       "      <td>Haunted House</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt10402510</td>\n",
       "      <td>en</td>\n",
       "      <td>Haunted House</td>\n",
       "      <td>Three Paranormal Investigators spend the night...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/q72Scu36kQzoZX8TQ9vxnCLqDk1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>2019</td>\n",
       "      <td>Haunted House (2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002264</th>\n",
       "      <td>664755</td>\n",
       "      <td>Fuck You, Purdue</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>1987-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>Fuck You, Purdue</td>\n",
       "      <td>A 1987 video by Cecilia Dougherty</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987</td>\n",
       "      <td>Fuck You, Purdue (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002265</th>\n",
       "      <td>664756</td>\n",
       "      <td>These Are the Rules</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>1983-03-03</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>These Are the Rules</td>\n",
       "      <td>In These Are the Rules, Doug Hall enacted an a...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983</td>\n",
       "      <td>These Are the Rules (1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002266</th>\n",
       "      <td>1254168</td>\n",
       "      <td>The Burden</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt3858764</td>\n",
       "      <td>en</td>\n",
       "      <td>The Burden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>The Burden (&lt;NA&gt;)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002267 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  ...                            title_year\n",
       "0          27205  ...                      Inception (2010)\n",
       "1         157336  ...                   Interstellar (2014)\n",
       "2            155  ...                The Dark Knight (2008)\n",
       "3          19995  ...                         Avatar (2009)\n",
       "4          24428  ...                   The Avengers (2012)\n",
       "...          ...  ...                                   ...\n",
       "1002262   664753  ...  Dead Kennedys: Live in Vienna (1982)\n",
       "1002263   664754  ...                  Haunted House (2019)\n",
       "1002264   664755  ...               Fuck You, Purdue (1987)\n",
       "1002265   664756  ...            These Are the Rules (1983)\n",
       "1002266  1254168  ...                     The Burden (<NA>)\n",
       "\n",
       "[1002267 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order to create a robust key \"title_year to join with the movielens dataset\"\n",
    "tmdb_df['release_date'] = pd.to_datetime(tmdb_df['release_date'], errors='coerce')\n",
    "tmdb_df['year'] = tmdb_df['release_date'].dt.year.astype('Int64').astype(str).replace('nan', '')\n",
    "tmdb_df['title_year'] = tmdb_df.apply(lambda x: f\"{x['title']} ({x['year']})\" if x['year'] else x['title'], axis=1)\n",
    "tmdb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n"
     ]
    }
   ],
   "source": [
    "df_movies = pd.read_csv('ml-1m/movies.csv', sep='::', engine='python', encoding='ISO-8859-1', header=None, names=['MovieID', 'Title', 'Genres']) #sohai give us 3 different files so need read them separately\n",
    "print(df_movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('ml-1m/ratings.csv', sep='::', engine='python', encoding='ISO-8859-1', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp']) # ^same\n",
    "print(df_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID Gender  Age  Occupation ZipCode\n",
      "0       1      F    1          10   48067\n",
      "1       2      M   56          16   70072\n",
      "2       3      M   25          15   55117\n",
      "3       4      M   45           7   02460\n",
      "4       5      M   25          20   55455\n"
     ]
    }
   ],
   "source": [
    "df_users = pd.read_csv('ml-1m/users.csv', sep='::', engine='python', encoding='ISO-8859-1', header=None, names=['UserID', 'Gender', 'Age', 'Occupation','ZipCode']) # ^same\n",
    "print(df_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "      <td>Weekend at Bernie's (1989)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "      <td>Crying Game, The (1992)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "      <td>Welcome to the Dollhouse (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "      <td>Sophie's Choice (1982)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "      <td>E.T. the Extra-Terrestrial (1982)</td>\n",
       "      <td>Children's|Drama|Fantasy|Sci-Fi</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  MovieID  Rating  Timestamp  ... Gender Age Occupation  ZipCode\n",
       "0             1     1193       5  978300760  ...      F   1         10    48067\n",
       "1             1      661       3  978302109  ...      F   1         10    48067\n",
       "2             1      914       3  978301968  ...      F   1         10    48067\n",
       "3             1     3408       4  978300275  ...      F   1         10    48067\n",
       "4             1     2355       5  978824291  ...      F   1         10    48067\n",
       "...         ...      ...     ...        ...  ...    ...  ..        ...      ...\n",
       "1000204    6040     1091       1  956716541  ...      M  25          6    11106\n",
       "1000205    6040     1094       5  956704887  ...      M  25          6    11106\n",
       "1000206    6040      562       5  956704746  ...      M  25          6    11106\n",
       "1000207    6040     1096       4  956715648  ...      M  25          6    11106\n",
       "1000208    6040     1097       4  956715569  ...      M  25          6    11106\n",
       "\n",
       "[1000209 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_combined = pd.merge(pd.merge(df_ratings, df_movies, on='MovieID'), df_users, on='UserID') #this is the merged version of the MovieLens Dataset\n",
    "df_ml_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         UserID  MovieID  ...  year                              title_year\n",
      "0             1     1193  ...  1975  One Flew Over the Cuckoo's Nest (1975)\n",
      "1             1      661  ...  1996        James and the Giant Peach (1996)\n",
      "2             1      914  ...  1964                     My Fair Lady (1964)\n",
      "3             1     3408  ...  2000                  Erin Brockovich (2000)\n",
      "4             1     2355  ...   NaN                                     NaN\n",
      "...         ...      ...  ...   ...                                     ...\n",
      "1012483    6040     1091  ...  1989              Weekend at Bernie's (1989)\n",
      "1012484    6040     1094  ...   NaN                                     NaN\n",
      "1012485    6040      562  ...   NaN                                     NaN\n",
      "1012486    6040     1096  ...  1982                  Sophie's Choice (1982)\n",
      "1012487    6040     1097  ...  1982       E.T. the Extra-Terrestrial (1982)\n",
      "\n",
      "[1012488 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#now to finally merge the datasets\n",
    "merged_df = pd.merge(df_ml_combined, tmdb_df, left_on='Title', right_on='title_year', how='left') #main dataset\n",
    "merged_df\n",
    "print(merged_df)   #use Genres from movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UserID', 'MovieID', 'Rating', 'Timestamp', 'Title', 'Genres', 'Gender',\n",
      "       'Age', 'Occupation', 'ZipCode', 'id', 'title', 'vote_average',\n",
      "       'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult',\n",
      "       'backdrop_path', 'budget', 'homepage', 'imdb_id', 'original_language',\n",
      "       'original_title', 'overview', 'popularity', 'poster_path', 'tagline',\n",
      "       'genres', 'production_companies', 'production_countries',\n",
      "       'spoken_languages', 'year', 'title_year'],\n",
      "      dtype='object')\n",
      "Number of NA values in the UserID column: 0\n",
      "Columns with NA values: ['overview', 'tagline', 'original_language', 'release_date', 'runtime', 'vote_average', 'vote_count', 'production_companies', 'production_countries', 'spoken_languages', 'year']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)\n",
    "# Counting how many NA values are in the 'UserID' column\n",
    "user_id_na_count = merged_df['UserID'].isna().sum()\n",
    "\n",
    "print(\"Number of NA values in the UserID column:\", user_id_na_count)\n",
    "# Assuming 'df' is your DataFrame\n",
    "important_columns = ['Title', 'Genres', 'overview', 'tagline', 'original_language', 'release_date', 'runtime', 'vote_average', 'vote_count', 'production_companies', 'production_countries', 'spoken_languages', 'year']\n",
    "\n",
    "# Check for any NA values in these columns\n",
    "na_columns = merged_df[important_columns].isna().any()\n",
    "\n",
    "# Print columns with NA values\n",
    "print(\"Columns with NA values:\", na_columns[na_columns].index.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cindy\\AppData\\Local\\Temp\\ipykernel_7268\\221871889.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Merged_df.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'UserID', 'MovieID', 'Rating', 'Timestamp', 'Title',\n",
      "       'Genres', 'Gender', 'Age', 'Occupation', 'ZipCode', 'Movie_Title',\n",
      "       'Movie_Year', 'id', 'title', 'vote_average', 'vote_count', 'status',\n",
      "       'release_date', 'revenue', 'runtime', 'adult', 'backdrop_path',\n",
      "       'budget', 'homepage', 'imdb_id', 'original_language', 'original_title',\n",
      "       'overview', 'popularity', 'poster_path', 'tagline', 'genres',\n",
      "       'production_companies', 'production_countries', 'spoken_languages',\n",
      "       'year', 'title_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Merged_df.csv')\n",
    "df.describe()\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  UserID  ...    year                              title_year\n",
      "0                0       1  ...  1975.0  One Flew Over the Cuckoo's Nest (1975)\n",
      "1                1       1  ...  1996.0        James and the Giant Peach (1996)\n",
      "2                2       1  ...  1964.0                     My Fair Lady (1964)\n",
      "3                3       1  ...  2000.0                  Erin Brockovich (2000)\n",
      "4                4       1  ...  1998.0                     A Bug's Life (1998)\n",
      "...            ...     ...  ...     ...                                     ...\n",
      "995650      994980    6040  ...  1992.0                  The Crying Game (1992)\n",
      "995651      994981    6040  ...  1992.0                  The Crying Game (1992)\n",
      "995652      994982    6040  ...  1996.0         Welcome to the Dollhouse (1996)\n",
      "995653      994983    6040  ...  1982.0                  Sophie's Choice (1982)\n",
      "995654      994984    6040  ...  1982.0       E.T. the Extra-Terrestrial (1982)\n",
      "\n",
      "[995655 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'merged_df' is your DataFrame\n",
    "merged_df = df\n",
    "content_merged_df = merged_df.drop(['genres', 'poster_path', 'backdrop_path','Age', 'Gender', 'homepage','Occupation', 'ZipCode'], axis=1)\n",
    "content_merged_df = content_merged_df.drop_duplicates().reset_index(drop=True) #no duplicates since row numbers remained the same, timestamp used for temporal analysis\n",
    "print(content_merged_df)\n",
    "#content_merged_df.to_csv('content.csv', index=False)\n",
    "\n",
    "content_merged_df['Genres'] = content_merged_df['Genres'].apply(lambda x: x.split('|') if pd.notnull(x) else []) # make genres a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ genre_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │ genre_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m640,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ genre_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,216\u001b[0m │ genre_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │      \u001b[38;5;34m2,322\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,050</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660,050\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,050</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m660,050\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m24892/24892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6ms/step - accuracy: 0.1532 - loss: 40136.3242 - val_accuracy: 0.2095 - val_loss: 268520.9062\n",
      "Epoch 2/5\n",
      "\u001b[1m24892/24892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 6ms/step - accuracy: 0.1507 - loss: 403722.2188 - val_accuracy: 0.0383 - val_loss: 861721.2500\n",
      "Epoch 3/5\n",
      "\u001b[1m24892/24892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 5ms/step - accuracy: 0.1515 - loss: 1108906.2500 - val_accuracy: 0.2557 - val_loss: 1430489.5000\n",
      "Epoch 4/5\n",
      "\u001b[1m24892/24892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 5ms/step - accuracy: 0.1515 - loss: 2142906.0000 - val_accuracy: 0.0177 - val_loss: 4458455.5000\n",
      "Epoch 5/5\n",
      "\u001b[1m24892/24892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5ms/step - accuracy: 0.1518 - loss: 3577516.7500 - val_accuracy: 0.2557 - val_loss: 4516542.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: combined_dense. Existing layers are: ['text_input', 'embedding_2', 'genre_input', 'global_average_pooling1d_1', 'dense_3', 'concatenate_1', 'dense_4', 'dense_5'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Make sure to use the right layer name that you've defined for your embeddings\u001b[39;00m\n\u001b[0;32m     68\u001b[0m embedding_layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_dense\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 69\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_layer_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Predict to get the embeddings\u001b[39;00m\n\u001b[0;32m     72\u001b[0m movie_embeddings \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mpredict([overview_padded, genres_encoded])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     arguments_context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arguments_context:\n\u001b[1;32m--> 122\u001b[0m     arguments_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arguments_context)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Get original error message and append information to it.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\models\\model.py:208\u001b[0m, in \u001b[0;36mget_layer\u001b[1;34m(self, name, index)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: combined_dense. Existing layers are: ['text_input', 'embedding_2', 'genre_input', 'global_average_pooling1d_1', 'dense_3', 'concatenate_1', 'dense_4', 'dense_5']."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "# Example DataFrame columns: 'MovieID', 'Title', 'Genres', 'Overview', ...\n",
    "\n",
    "# Preprocess text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "\n",
    "# Fill NaN values with an empty string or some placeholder text before tokenization\n",
    "content_merged_df['overview'].fillna(\"\", inplace=True)\n",
    "\n",
    "# Now proceed with the text tokenization\n",
    "tokenizer.fit_on_texts(content_merged_df['overview'])\n",
    "overview_sequences = tokenizer.texts_to_sequences(content_merged_df['overview'])\n",
    "overview_padded = pad_sequences(overview_sequences, maxlen=100)\n",
    "\n",
    "\n",
    "# Preprocess genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(content_merged_df['Genres'])\n",
    "\n",
    "# Text input branch\n",
    "text_input = Input(shape=(100,), dtype='int32', name='text_input')  # This line is correct as is\n",
    "text_embedding = Embedding(input_dim=10000, output_dim=64)(text_input)  # Removed the incorrect argument\n",
    "text_pooled = GlobalAveragePooling1D()(text_embedding)\n",
    "\n",
    "\n",
    "# Genre input branch\n",
    "genre_input = Input(shape=(genres_encoded.shape[1],), name='genre_input')\n",
    "genre_dense = Dense(64, activation='relu')(genre_input)\n",
    "\n",
    "# Combine branches\n",
    "combined = concatenate([text_pooled, genre_dense])\n",
    "combined_dense = Dense(128, activation='relu')(combined)\n",
    "output = Dense(genres_encoded.shape[1], activation='softmax')(combined_dense)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[text_input, genre_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# overview_padded and genres_encoded need to be split separately\n",
    "X_train_overview, X_test_overview, y_train_genres, y_test_genres = train_test_split(\n",
    "    overview_padded, genres_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# The model expects a list of numpy arrays as input, so we need to split each input array separately\n",
    "X_train_genre = genres_encoded[:len(X_train_overview)]\n",
    "X_test_genre = genres_encoded[len(X_train_overview):]\n",
    "\n",
    "# Train the model. Notice that model.fit expects a list of inputs for the model's multiple inputs\n",
    "model.fit([X_train_overview, X_train_genre], y_train_genres, epochs=5, validation_data=([X_test_overview, X_test_genre], y_test_genres))\n",
    "\n",
    "# Make sure to use the right layer name that you've defined for your embeddings\n",
    "embedding_layer_name = 'combined_dense'\n",
    "embedding_model = Model(inputs=model.input, outputs=model.get_layer(embedding_layer_name).output)\n",
    "\n",
    "# Predict to get the embeddings\n",
    "movie_embeddings = embedding_model.predict([overview_padded, genres_encoded])\n",
    "\n",
    "# embedding_model = Model(inputs=model.input,\n",
    "#                         outputs=model.get_layer('combined_dense').output)\n",
    "# movie_embeddings = embedding_model.predict([overview_padded, genres_encoded])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_movies(movie_id, top_n=5):\n",
    "    # Assuming the MovieID is the index in content_merged_df\n",
    "    movie_idx = content_merged_df.index[content_merged_df['MovieID'] == movie_id][0]\n",
    "    movie_embedding = movie_embeddings[movie_idx].reshape(1, -1)\n",
    "    cos_similarities = cosine_similarity(movie_embedding, movie_embeddings)[0]\n",
    "    \n",
    "    # Get the top_n most similar movies\n",
    "    similar_movie_idxs = np.argsort(cos_similarities)[-top_n-1:-1][::-1]\n",
    "    \n",
    "    # Return their titles\n",
    "    return content_merged_df.iloc[similar_movie_idxs]['Title']\n",
    "\n",
    "# Example usage\n",
    "given_movie_id = 1193  # Replace with an actual MovieID from your dataset\n",
    "recommended_titles = recommend_movies(given_movie_id)\n",
    "print(\"Recommended Movies:\", recommended_titles.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the content table: (995655, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>children</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>documentary</th>\n",
       "      <th>drama</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fi</th>\n",
       "      <th>film</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>noir</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action  adventure  animation  children  comedy  crime  documentary  drama  \\\n",
       "0       0          0          0         0       0      0            0      1   \n",
       "1       0          0          1         1       0      0            0      0   \n",
       "2       0          0          0         0       0      0            0      0   \n",
       "3       0          0          0         0       0      0            0      1   \n",
       "4       0          0          1         1       1      0            0      0   \n",
       "\n",
       "   fantasy  fi  film  horror  musical  mystery  noir  romance  sci  thriller  \\\n",
       "0        0   0     0       0        0        0     0        0    0         0   \n",
       "1        0   0     0       0        1        0     0        0    0         0   \n",
       "2        0   0     0       0        1        0     0        1    0         0   \n",
       "3        0   0     0       0        0        0     0        0    0         0   \n",
       "4        0   0     0       0        0        0     0        0    0         0   \n",
       "\n",
       "   war  western  \n",
       "0    0        0  \n",
       "1    0        0  \n",
       "2    0        0  \n",
       "3    0        0  \n",
       "4    0        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the 'Genres' column\n",
    "genres = vectorizer.fit_transform(content_merged_df['Genres']).toarray()\n",
    "\n",
    "# Create a DataFrame from the transformed genres\n",
    "contents = pd.DataFrame(genres, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the shape of the content table\n",
    "print('Shape of the content table:', contents.shape)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn_algo = NearestNeighbors(metric='cosine')\n",
    "nn_algo.fit(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.hist = [] \n",
    "        self.ishist = False\n",
    "\n",
    "    def recommend_on_movie(self, movie, n_recommend=10):\n",
    "        \"\"\"\n",
    "        Recommend movies similar to a given movie.\n",
    "\n",
    "        Parameters:\n",
    "            movie (str): The title of the movie.\n",
    "            n_recommend (int): Number of recommendations to return.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of recommended movie titles.\n",
    "        \"\"\"\n",
    "        self.ishist = True\n",
    "        iloc = content_merged_df[content_merged_df['Title'] == movie].index[0]\n",
    "        self.hist.append(iloc)\n",
    "        distance, neighbors = nn_algo.kneighbors([contents.iloc[iloc]], n_neighbors=n_recommend+1)\n",
    "        recommeds = [content_merged_df.iloc[i]['Title'] for i in neighbors[0] if i not in [iloc]]\n",
    "        return recommeds[:n_recommend]\n",
    "    \n",
    "    def recommend_on_history(self, n_recommend=10):\n",
    "        \"\"\"\n",
    "        Recommend movies based on the user's watch history.\n",
    "\n",
    "        Parameters:\n",
    "            n_recommend (int): Number of recommendations to return.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of recommended movie titles.\n",
    "        \"\"\"\n",
    "        if not self.ishist:\n",
    "            return print('No history found')\n",
    "        \n",
    "        unique_movies = set(content_merged_df['Title'])  # Create a set of unique movie titles\n",
    "        \n",
    "        history = np.array([list(contents.iloc[iloc]) for iloc in self.hist])\n",
    "        distance, neighbors = nn_algo.kneighbors([np.average(history, axis=0)], n_neighbors=len(unique_movies))\n",
    "        \n",
    "        recommended_movies = []\n",
    "        recommended_indices = set()  # To store indices of recommended movies\n",
    "        \n",
    "        for i in neighbors[0]:\n",
    "            # Check if the movie is not in user's watch history, not already recommended, and is in the unique movie set\n",
    "            if i not in self.hist and i not in recommended_indices and content_merged_df.iloc[i]['Title'] in unique_movies:\n",
    "                recommended_movies.append(content_merged_df.iloc[i]['Title'])\n",
    "                recommended_indices.add(i)\n",
    "                if len(recommended_movies) == n_recommend:\n",
    "                    break\n",
    "                    \n",
    "        # Filter out duplicates from recommended movies\n",
    "        unique_recommended_movies = []\n",
    "        for movie in recommended_movies:\n",
    "            if movie not in unique_recommended_movies:\n",
    "                unique_recommended_movies.append(movie)\n",
    "        \n",
    "        return unique_recommended_movies[:n_recommend]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1's watch history:\n",
      "[\"One Flew Over the Cuckoo's Nest (1975)\", 'James and the Giant Peach (1996)', 'My Fair Lady (1964)', 'Erin Brockovich (2000)', \"A Bug's Life (1998)\", 'The Princess Bride (1987)', 'Ben-Hur (1959)', 'A Christmas Story (1983)', 'Snow White and the Seven Dwarfs (1937)', 'The Wizard of Oz (1939)', 'Beauty and the Beast (1991)', 'Gigi (1958)', 'Miracle on 34th Street (1947)', \"Ferris Bueller's Day Off (1986)\", 'The Sound of Music (1965)', 'Airplane! (1980)', 'Tarzan (1999)', 'Bambi (1942)', 'Awakenings (1990)', 'Big (1988)', 'Pleasantville (1998)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'Back to the Future (1985)', \"Schindler's List (1993)\", 'Meet Joe Black (1998)', 'E.T. the Extra-Terrestrial (1982)', 'Titanic (1997)', 'Ponette (1996)', 'A Close Shave (1995)', 'Antz (1998)', 'Girl, Interrupted (1999)', 'The Hunchback of Notre Dame (1996)', 'The Hunchback of Notre Dame (1996)', 'The Hunchback of Notre Dame (1996)', 'The Hunchback of Notre Dame (1996)', 'The Hunchback of Notre Dame (1996)', 'The Last Days of Disco (1998)', 'Cinderella (1950)', 'The Sixth Sense (1999)', 'Apollo 13 (1995)', 'Toy Story (1995)', 'Rain Man (1988)', 'Driving Miss Daisy (1989)', 'Run Lola Run (1998)', 'Star Wars: Episode IV - A New Hope (1977)', 'Mary Poppins (1964)', 'Dumbo (1941)', 'To Kill a Mockingbird (1962)', 'Saving Private Ryan (1998)', 'The Secret Garden (1993)', 'Toy Story 2 (1999)', 'Fargo (1996)', 'Dead Poets Society (1989)']\n"
     ]
    }
   ],
   "source": [
    "def generate_user_watch_history(user_id, df):\n",
    "    \"\"\"\n",
    "    Generate a particular user's watch history based on their user ID.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): The ID of the user.\n",
    "        df (pandas.DataFrame): The DataFrame containing the merged data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of movie titles representing the user's watch history.\n",
    "    \"\"\"\n",
    "    user_history = df[df['UserID'] == user_id]['Title'].tolist()\n",
    "    return user_history\n",
    "\n",
    "# Example usage:\n",
    "user_id = 1  # Replace with the desired user ID\n",
    "watch_history = generate_user_watch_history(user_id, df)\n",
    "print(f\"User {user_id}'s watch history:\")\n",
    "print(watch_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def create_recommender_for_user(user_id, df):\n",
    "    \"\"\"\n",
    "    Create a recommender for a specific user's watch history.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): The ID of the user.\n",
    "        df (pandas.DataFrame): The DataFrame containing the merged data.\n",
    "\n",
    "    Returns:\n",
    "        Recommender: A Recommender instance populated with the user's watch history.\n",
    "    \"\"\"\n",
    "    user_watch_history = generate_user_watch_history(user_id, df)\n",
    "    \n",
    "    # Create a new Recommender instance\n",
    "    user_recommender = Recommender()\n",
    "    \n",
    "    # Populate the Recommender instance with the user's watch history\n",
    "    for movie_title in user_watch_history:\n",
    "        user_recommender.recommend_on_movie(movie_title)\n",
    "    \n",
    "    return user_recommender\n",
    "\n",
    "# Create a Recommender instance for user 1\n",
    "user2_recommender = create_recommender_for_user(3, df)\n",
    "\n",
    "\n",
    "# Now you have a Recommender instance for user 1 containing their watch history\n",
    "# You can use this Recommender instance to make recommendations for user 1 based on their history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Three Musketeers (1993)',\n",
       " 'The Golden Child (1986)',\n",
       " 'Operation Condor (1990)',\n",
       " 'Mystery Men (1999)']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2_recommender.recommend_on_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'overview' and 'tagline' are your textual columns\n",
    "content_merged_df['combined_text'] = content_merged_df['overview'].fillna('') + ' ' + content_merged_df['tagline'].fillna('') + ' ' + content_merged_df['Title']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(content_merged_df['combined_text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  UserID  MovieID  Rating           Timestamp  \\\n",
      "995584      994914    6040      858       4 2000-04-25 23:05:32   \n",
      "995319      994650    6040      593       5 2000-04-25 23:05:54   \n",
      "995598      994928    6040     2384       4 2000-04-25 23:05:54   \n",
      "995637      994967    6040     2019       5 2000-04-25 23:06:17   \n",
      "995453      994783    6040     1961       4 2000-04-25 23:06:17   \n",
      "...            ...     ...      ...     ...                 ...   \n",
      "312909      312699    1875     1235       3 2000-12-02 14:34:55   \n",
      "312644      312434    1875     3072       4 2000-12-02 14:34:55   \n",
      "312817      312607    1875     3361       4 2000-12-02 14:35:12   \n",
      "312818      312608    1875     3362       4 2000-12-02 14:35:12   \n",
      "312615      312405    1875      909       3 2000-12-02 14:35:12   \n",
      "\n",
      "                                  Title              Genres  \\\n",
      "995584             The Godfather (1972)  Action|Crime|Drama   \n",
      "995319  The Silence of the Lambs (1991)      Drama|Thriller   \n",
      "995598     Babe: Pig in the City (1998)   Children's|Comedy   \n",
      "995637             Seven Samurai (1954)        Action|Drama   \n",
      "995453                  Rain Man (1988)               Drama   \n",
      "...                                 ...                 ...   \n",
      "312909          Harold and Maude (1971)              Comedy   \n",
      "312644                Moonstruck (1987)              Comedy   \n",
      "312817               Bull Durham (1988)              Comedy   \n",
      "312818         Dog Day Afternoon (1975)  Comedy|Crime|Drama   \n",
      "312615             The Apartment (1960)        Comedy|Drama   \n",
      "\n",
      "                     Movie_Title  Movie_Year        id  ...  \\\n",
      "995584            The  Godfather        1972     238.0  ...   \n",
      "995319  The Silence of the Lambs        1991     274.0  ...   \n",
      "995598     Babe: Pig in the City        1998    9447.0  ...   \n",
      "995637             Seven Samurai        1954     346.0  ...   \n",
      "995453                  Rain Man        1988     380.0  ...   \n",
      "...                          ...         ...       ...  ...   \n",
      "312909          Harold and Maude        1971     343.0  ...   \n",
      "312644                Moonstruck        1987    2039.0  ...   \n",
      "312817               Bull Durham        1988     287.0  ...   \n",
      "312818         Dog Day Afternoon        1975     968.0  ...   \n",
      "312615            The  Apartment        1960  364520.0  ...   \n",
      "\n",
      "                  original_title  \\\n",
      "995584             The Godfather   \n",
      "995319  The Silence of the Lambs   \n",
      "995598     Babe: Pig in the City   \n",
      "995637                      七人の侍   \n",
      "995453                  Rain Man   \n",
      "...                          ...   \n",
      "312909          Harold and Maude   \n",
      "312644                Moonstruck   \n",
      "312817               Bull Durham   \n",
      "312818         Dog Day Afternoon   \n",
      "312615            La garçonnière   \n",
      "\n",
      "                                                 overview  popularity  \\\n",
      "995584  Spanning the years 1945 to 1955, a chronicle o...     158.448   \n",
      "995319  Clarice Starling is a top student at the FBI's...       9.119   \n",
      "995598  Babe, fresh from his victory in the sheepherdi...      18.537   \n",
      "995637  A samurai answers a village's request for prot...      36.579   \n",
      "995453  When car dealer Charlie Babbitt learns that hi...      21.798   \n",
      "...                                                   ...         ...   \n",
      "312909  The young Harold lives in his own world of sui...      23.191   \n",
      "312644  No sooner does Italian-American widow Loretta ...      20.181   \n",
      "312817  Veteran catcher Crash Davis is brought to the ...      13.927   \n",
      "312818  Based on the true story of would-be Brooklyn b...      18.585   \n",
      "312615  A building instructor cheats on his wife with ...       1.257   \n",
      "\n",
      "                                                  tagline  \\\n",
      "995584                         An offer you can't refuse.   \n",
      "995319  To enter the mind of a killer she must challen...   \n",
      "995598                This little pig went to the city...   \n",
      "995637  The Mighty Warriors Who Became the Seven Natio...   \n",
      "995453    A journey through understanding and fellowship.   \n",
      "...                                                   ...   \n",
      "312909  They were meant to be. But exactly what they w...   \n",
      "312644                                Life. Family. Love.   \n",
      "312817  Romance is a lot like baseball. It's not wheth...   \n",
      "312818  Anything can happen during the dog days of sum...   \n",
      "312615                                                NaN   \n",
      "\n",
      "                                     production_companies  \\\n",
      "995584                      Paramount, Alfran Productions   \n",
      "995319      Orion Pictures, Strong Heart/Demme Production   \n",
      "995598     Kennedy Miller Productions, Universal Pictures   \n",
      "995637                                               TOHO   \n",
      "995453              United Artists, Star Partners II Ltd.   \n",
      "...                                                   ...   \n",
      "312909                                          Paramount   \n",
      "312644                 Star Partners, Metro-Goldwyn-Mayer   \n",
      "312817  The Mount Company, Metro-Goldwyn-Mayer, Orion ...   \n",
      "312818  Artists Entertainment Complex, Warner Bros. Pi...   \n",
      "312615                                            Amoroso   \n",
      "\n",
      "            production_countries         spoken_languages    year  \\\n",
      "995584  United States of America  English, Italian, Latin  1972.0   \n",
      "995319  United States of America                  English  1991.0   \n",
      "995598                 Australia                  English  1998.0   \n",
      "995637                     Japan                 Japanese  1954.0   \n",
      "995453  United States of America         Italian, English  1988.0   \n",
      "...                          ...                      ...     ...   \n",
      "312909  United States of America                  English  1971.0   \n",
      "312644  United States of America         English, Italian  1987.0   \n",
      "312817  United States of America                  English  1988.0   \n",
      "312818  United States of America                  English  1975.0   \n",
      "312615                     Italy                  Italian  1960.0   \n",
      "\n",
      "                             title_year  \\\n",
      "995584             The Godfather (1972)   \n",
      "995319  The Silence of the Lambs (1991)   \n",
      "995598     Babe: Pig in the City (1998)   \n",
      "995637             Seven Samurai (1954)   \n",
      "995453                  Rain Man (1988)   \n",
      "...                                 ...   \n",
      "312909          Harold and Maude (1971)   \n",
      "312644                Moonstruck (1987)   \n",
      "312817               Bull Durham (1988)   \n",
      "312818         Dog Day Afternoon (1975)   \n",
      "312615             The Apartment (1960)   \n",
      "\n",
      "                                            combined_text  \n",
      "995584  Spanning the years 1945 to 1955, a chronicle o...  \n",
      "995319  Clarice Starling is a top student at the FBI's...  \n",
      "995598  Babe, fresh from his victory in the sheepherdi...  \n",
      "995637  A samurai answers a village's request for prot...  \n",
      "995453  When car dealer Charlie Babbitt learns that hi...  \n",
      "...                                                   ...  \n",
      "312909  The young Harold lives in his own world of sui...  \n",
      "312644  No sooner does Italian-American widow Loretta ...  \n",
      "312817  Veteran catcher Crash Davis is brought to the ...  \n",
      "312818  Based on the true story of would-be Brooklyn b...  \n",
      "312615  A building instructor cheats on his wife with ...  \n",
      "\n",
      "[796524 rows x 31 columns]\n",
      "        Unnamed: 0  UserID  MovieID  Rating           Timestamp  \\\n",
      "312614      312404    1875      909       3 2000-12-02 14:35:12   \n",
      "312902      312692    1875     1080       3 2000-12-02 14:35:12   \n",
      "312848      312638    1875       21       4 2000-12-02 14:35:27   \n",
      "312720      312510    1875     3671       4 2000-12-02 14:35:27   \n",
      "312853      312643    1875     1028       3 2000-12-02 14:35:37   \n",
      "...            ...     ...      ...     ...                 ...   \n",
      "822042      821495    4958     2399       1 2003-02-28 17:45:38   \n",
      "821688      821141    4958     1407       5 2003-02-28 17:47:23   \n",
      "821980      821433    4958     2634       3 2003-02-28 17:49:08   \n",
      "821973      821426    4958     3264       4 2003-02-28 17:49:08   \n",
      "821853      821306    4958     1924       4 2003-02-28 17:49:50   \n",
      "\n",
      "                                      Title                        Genres  \\\n",
      "312614                 The Apartment (1960)                  Comedy|Drama   \n",
      "312902  Monty Python's Life of Brian (1979)                        Comedy   \n",
      "312848                    Get Shorty (1995)           Action|Comedy|Drama   \n",
      "312720               Blazing Saddles (1974)                Comedy|Western   \n",
      "312853                  Mary Poppins (1964)     Children's|Comedy|Musical   \n",
      "...                                     ...                           ...   \n",
      "822042        Santa Claus: The Movie (1985)  Adventure|Children's|Fantasy   \n",
      "821688                        Scream (1996)               Horror|Thriller   \n",
      "821980                     The Mummy (1959)                        Horror   \n",
      "821973      Buffy the Vampire Slayer (1992)                 Comedy|Horror   \n",
      "821853       Plan 9 from Outer Space (1958)                 Horror|Sci-Fi   \n",
      "\n",
      "                         Movie_Title  Movie_Year       id  ...  \\\n",
      "312614                The  Apartment        1960    284.0  ...   \n",
      "312902  Monty Python's Life of Brian        1979    583.0  ...   \n",
      "312848                    Get Shorty        1995   8012.0  ...   \n",
      "312720               Blazing Saddles        1974  11072.0  ...   \n",
      "312853                  Mary Poppins        1964    433.0  ...   \n",
      "...                              ...         ...      ...  ...   \n",
      "822042        Santa Claus: The Movie        1985  13764.0  ...   \n",
      "821688                        Scream        1996   4232.0  ...   \n",
      "821980                    The  Mummy        1959  18990.0  ...   \n",
      "821973      Buffy the Vampire Slayer        1992  10206.0  ...   \n",
      "821853       Plan 9 from Outer Space        1958  10513.0  ...   \n",
      "\n",
      "                  original_title  \\\n",
      "312614             The Apartment   \n",
      "312902             Life of Brian   \n",
      "312848                Get Shorty   \n",
      "312720           Blazing Saddles   \n",
      "312853              Mary Poppins   \n",
      "...                          ...   \n",
      "822042    Santa Claus: The Movie   \n",
      "821688                    Scream   \n",
      "821980                 The Mummy   \n",
      "821973  Buffy the Vampire Slayer   \n",
      "821853   Plan 9 from Outer Space   \n",
      "\n",
      "                                                 overview  popularity  \\\n",
      "312614  Bud Baxter is a minor clerk in a huge New York...      24.186   \n",
      "312902  Brian Cohen is an average young Jewish man, bu...      33.204   \n",
      "312848  Chili Palmer is a Miami mobster who gets sent ...      12.300   \n",
      "312720  A town—where everyone seems to be named Johnso...      21.070   \n",
      "312853  Mr Banks is looking for a nanny for his two mi...      27.399   \n",
      "...                                                   ...         ...   \n",
      "822042  The first half of this film, set hundreds of y...      10.367   \n",
      "821688  A year after the murder of her mother, Sidney ...      61.423   \n",
      "821980  One by one the archaeologists who discover the...      11.412   \n",
      "821973  Blonde, bouncy Buffy is your typical high scho...      22.217   \n",
      "821853  In California, an old man grieves the loss of ...      10.206   \n",
      "\n",
      "                                                  tagline  \\\n",
      "312614  Movie-wise, there has never been anything like...   \n",
      "312902  He wasn't the messiah. He was a very naughty boy.   \n",
      "312848                             Attitude plays a part.   \n",
      "312720                   Never give a saga an even break!   \n",
      "312853           It's supercalifragilisticexpialidocious!   \n",
      "...                                                   ...   \n",
      "822042  You'd better watch out! This year he REALLY IS...   \n",
      "821688  Someone has taken their love of scary movies o...   \n",
      "821980           Torn from the tomb to terrify the world!   \n",
      "821973              She knows a sucker when she sees one.   \n",
      "821853  Unspeakable horrors from outer space paralyze ...   \n",
      "\n",
      "                                     production_companies  \\\n",
      "312614                The Mirisch Company, United Artists   \n",
      "312902    HandMade Films, Python (Monty) Pictures Limited   \n",
      "312848                  Jersey Films, Metro-Goldwyn-Mayer   \n",
      "312720        Crossbow Productions, Warner Bros. Pictures   \n",
      "312853                            Walt Disney Productions   \n",
      "...                                                   ...   \n",
      "822042  TriStar Pictures, Calash Corporation, GGG, San...   \n",
      "821688      Dimension Films, Woods Entertainment, Miramax   \n",
      "821980                            Hammer Film Productions   \n",
      "821973     Sandollar, Kuzui Enterprises, 20th Century Fox   \n",
      "821853                                  Reynolds Pictures   \n",
      "\n",
      "            production_countries          spoken_languages    year  \\\n",
      "312614  United States of America                   English  1960.0   \n",
      "312902            United Kingdom            English, Latin  1979.0   \n",
      "312848  United States of America                   English  1995.0   \n",
      "312720  United States of America  Yiddish, German, English  1974.0   \n",
      "312853  United States of America                   English  1964.0   \n",
      "...                          ...                       ...     ...   \n",
      "822042  United States of America                   English  1985.0   \n",
      "821688  United States of America                   English  1996.0   \n",
      "821980            United Kingdom                   English  1959.0   \n",
      "821973  United States of America                   English  1992.0   \n",
      "821853  United States of America                   English  1959.0   \n",
      "\n",
      "                             title_year  \\\n",
      "312614             The Apartment (1960)   \n",
      "312902             Life of Brian (1979)   \n",
      "312848                Get Shorty (1995)   \n",
      "312720           Blazing Saddles (1974)   \n",
      "312853              Mary Poppins (1964)   \n",
      "...                                 ...   \n",
      "822042    Santa Claus: The Movie (1985)   \n",
      "821688                    Scream (1996)   \n",
      "821980                 The Mummy (1959)   \n",
      "821973  Buffy the Vampire Slayer (1992)   \n",
      "821853   Plan 9 from Outer Space (1959)   \n",
      "\n",
      "                                            combined_text  \n",
      "312614  Bud Baxter is a minor clerk in a huge New York...  \n",
      "312902  Brian Cohen is an average young Jewish man, bu...  \n",
      "312848  Chili Palmer is a Miami mobster who gets sent ...  \n",
      "312720  A town—where everyone seems to be named Johnso...  \n",
      "312853  Mr Banks is looking for a nanny for his two mi...  \n",
      "...                                                   ...  \n",
      "822042  The first half of this film, set hundreds of y...  \n",
      "821688  A year after the murder of her mother, Sidney ...  \n",
      "821980  One by one the archaeologists who discover the...  \n",
      "821973  Blonde, bouncy Buffy is your typical high scho...  \n",
      "821853  In California, an old man grieves the loss of ...  \n",
      "\n",
      "[199131 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#old training\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and 'Timestamp' is the column with Unix timestamps\n",
    "# Step 1: Convert 'Timestamp' to a datetime object\n",
    "content_merged_df['Timestamp'] = pd.to_datetime(content_merged_df['Timestamp'], unit='s')\n",
    "\n",
    "# Step 2: Sort the DataFrame by 'Timestamp' in ascending order\n",
    "content_merged_df = content_merged_df.sort_values(by='Timestamp', ascending=True)\n",
    "\n",
    "# Step 3: Determine the split point (e.g., 80% for training, 20% for test)\n",
    "split_point = int(len(content_merged_df) * 0.8)\n",
    "\n",
    "# Step 4: Split the dataset into training and test sets\n",
    "train_set = content_merged_df[:split_point]\n",
    "test_set = content_merged_df[split_point:]\n",
    "\n",
    "# You now have your training set and test set, with the test set containing the most recent data\n",
    "print(train_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Recommender by Karan Walanj: \n",
      "User name: Favorite Movie: The Hunt for Red October (1990)\n",
      "\n",
      "\n",
      "Films you might enjoy based on what user 25 watched: The Hunt for Red October (1990)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fugitive (1993)</td>\n",
       "      <td>0.697511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriot Games (1992)</td>\n",
       "      <td>0.658445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speed (1994)</td>\n",
       "      <td>0.635091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Recall (1990)</td>\n",
       "      <td>0.626389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>0.614651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Rock (1996)</td>\n",
       "      <td>0.612756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>0.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clear and Present Danger (1994)</td>\n",
       "      <td>0.611010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Die Hard 2 (1990)</td>\n",
       "      <td>0.603285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Matrix (1999)</td>\n",
       "      <td>0.602715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title  cosine_sim\n",
       "1                 The Fugitive (1993)    0.697511\n",
       "2                Patriot Games (1992)    0.658445\n",
       "3                        Speed (1994)    0.635091\n",
       "4                 Total Recall (1990)    0.626389\n",
       "5                     Die Hard (1988)    0.614651\n",
       "6                     The Rock (1996)    0.612756\n",
       "7   Terminator 2: Judgment Day (1991)    0.611300\n",
       "8     Clear and Present Danger (1994)    0.611010\n",
       "9                   Die Hard 2 (1990)    0.603285\n",
       "10                  The Matrix (1999)    0.602715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films you might enjoy with similar genre as The Hunt for Red October (1990)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27996\\3653791956.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m             .sort_values('genre_similarity', ascending=False)[:top_results])\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mgenerate_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_merged_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserID\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent_merged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Genres'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27996\\3653791956.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, UserID, top_results, cat)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcos_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_based_recom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtop_results\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Films you might enjoy with similar genre as\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     display(item_and_genre_based_recom(item_based_recom(df, top_movie), df[['Title']], cat)\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cosine_sim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             .sort_values('genre_similarity', ascending=False)[:top_results])\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27996\\3653791956.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cosine_df, movies_df, categories)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mitem_and_genre_based_recom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtop_cos_genre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre_similarity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpairwise_row_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cosine_sim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'genre_similarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27996\\3653791956.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mitem_and_genre_based_recom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtop_cos_genre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre_similarity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpairwise_row_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtop_cos_genre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cosine_sim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'genre_similarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27996\\3653791956.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(dataframe, row1, row2, column_names)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpairwise_row_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmatrix_row1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mmatrix_row2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_row1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix_row2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6289\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6290\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6291\u001b[0m         ):\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#old\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def item_based_recom(input_dataframe, input_film_name): \n",
    "    pivot_item_based = pd.pivot_table(input_dataframe, index='Title', columns=['UserID'], values='Rating')\n",
    "    sparse_pivot = sparse.csr_matrix(pivot_item_based.fillna(0)) \n",
    "    recommender = cosine_similarity(sparse_pivot) \n",
    "    recommender_df = pd.DataFrame(recommender, columns=pivot_item_based.index, index=pivot_item_based.index)\n",
    "    cosine_df = pd.DataFrame(recommender_df[input_film_name].sort_values(ascending=False)) \n",
    "    cosine_df.reset_index(level=0, inplace=True) \n",
    "    cosine_df.columns = ['Title', 'cosine_sim']\n",
    "    return cosine_df\n",
    "\n",
    "def item_and_genre_based_recom(cosine_df, movies_df, categories):\n",
    "    top_cos_genre = pd.merge(cosine_df, movies_df, on='Title')\n",
    "    top_cos_genre['genre_similarity'] = [pairwise_row_diff(top_cos_genre, 0, row, categories) for row in top_cos_genre.index.values]\n",
    "    return top_cos_genre[['Title', 'cosine_sim', 'genre_similarity']]\n",
    "\n",
    "def pairwise_row_diff(dataframe, row1, row2, column_names):\n",
    "    matrix_row1 = [[dataframe.loc[row1, cat] for cat in column_names.split('|')]] \n",
    "    matrix_row2 = [[dataframe.loc[row2, cat] for cat in column_names.split('|')]] \n",
    "    return round(cosine_similarity(matrix_row1, matrix_row2)[0][0], 5)\n",
    "\n",
    "def generate_recommendations(df, UserID, top_results=10, cat=None): \n",
    "    # Get the top movie based on the rating of the UserID\n",
    "    top_movie = df[df['UserID'] == UserID].sort_values(by='Rating', ascending=False)['Title'].iloc[0]\n",
    "    \n",
    "    print(\"Movie Recommender by Karan Walanj: \")\n",
    "    print(\"User name: \" + \"Favorite Movie:\", top_movie+'\\n\\n')\n",
    "    print(\"Films you might enjoy based on what user\", UserID, \"watched:\", top_movie)\n",
    "    cos_sim = item_based_recom(df, top_movie) \n",
    "    display(cos_sim[1:top_results+1])\n",
    "\n",
    "    print(\"Films you might enjoy with similar genre as\", top_movie)\n",
    "    display(item_and_genre_based_recom(item_based_recom(df, top_movie), df[['Title']], cat)\n",
    "            .sort_values('cosine_sim', ascending=False)[top_results:]\n",
    "            .sort_values('genre_similarity', ascending=False)[:top_results])\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "generate_recommendations(content_merged_df, UserID=25, top_results=10, cat=content_merged_df['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Assuming merged_df is already loaded with your data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: Preprocess the dataset with TF-IDF\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspoken_languages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduction_countries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduction_companies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtagline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Function to create a user profile\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10346\u001b[0m )\n\u001b[1;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Assuming merged_df is already loaded with your data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: Preprocess the dataset with TF-IDF\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspoken_languages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduction_countries\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduction_companies\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Function to create a user profile\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6637\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6631\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6632\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6633\u001b[0m     ]\n\u001b[0;32m   6635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6636\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6637\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6638\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:431\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    429\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:367\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m--> 367\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1860\u001b[0m, in \u001b[0;36mSingleBlockManager.from_blocks\u001b[1;34m(cls, blocks, axes)\u001b[0m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#old\n",
    "# #CONTENT BASED FILTERING \n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming merged_df is already loaded with your data\n",
    "\n",
    "# # Step 1: Preprocess the dataset with TF-IDF\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# merged_df['combined_features'] = merged_df[['Genres', 'spoken_languages', 'production_countries', 'production_companies', 'tagline', 'overview']].apply(lambda x: ' '.join(x.astype(str).values), axis=1)\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(merged_df['combined_features'])\n",
    "\n",
    "# # Function to create a user profile\n",
    "# # def create_user_profile(user_id, merged_df, tfidf_matrix, rating_threshold=4):\n",
    "#     user_data = merged_df[merged_df['UserID'] == user_id]\n",
    "#     # Filter movies that the user has rated above the threshold\n",
    "#     high_rating_indices = user_data[user_data['Rating'] > rating_threshold].index.tolist()\n",
    "    \n",
    "#     if not high_rating_indices:\n",
    "#         return np.array([])  # Return an empty array if no high-rated movies\n",
    "\n",
    "#     # We extract the rows from tfidf_matrix corresponding to high ratings\n",
    "#     # and compute the mean. Note: toarray() converts sparse matrix to dense\n",
    "#     # Ensure the result is a dense 2D array for compatibility with cosine_similarity\n",
    "#     user_profile = np.mean(tfidf_matrix[high_rating_indices].toarray(), axis=0)\n",
    "    \n",
    "#     # Ensure user_profile is 2D: (1, number_of_features)\n",
    "#     user_profile = user_profile.reshape(1, -1)\n",
    "    \n",
    "#     return user_profile\n",
    "\n",
    "\n",
    "# # Function to recommend movies based on the user profile\n",
    "# def recommend(user_profile, tfidf_matrix, merged_df, user_id, n_recommendations=5):\n",
    "#     if user_profile is None:\n",
    "#         return []\n",
    "\n",
    "#     # Calculate similarity between user profile and all movie profiles\n",
    "#     cosine_similarities = cosine_similarity(user_profile, tfidf_matrix)\n",
    "    \n",
    "#     # Get indices sorted by similarity (descending)\n",
    "#     similar_indices = cosine_similarities.argsort().flatten()[-n_recommendations*2:]\n",
    "    \n",
    "#     # Filter out movies the user has already watched/rated\n",
    "#     watched_movie_ids = set(merged_df[merged_df['UserID'] == user_id]['MovieID'])\n",
    "#     recommended_movie_ids = [idx for idx in similar_indices if merged_df.iloc[idx]['MovieID'] not in watched_movie_ids]\n",
    "    \n",
    "#     # Limit to the top N recommendations\n",
    "#     recommended_movie_ids = recommended_movie_ids[-n_recommendations:]\n",
    "#     return merged_df.iloc[recommended_movie_ids]['MovieID'].values\n",
    "\n",
    "# # Example usage\n",
    "# user_id = 1  # Replace with an actual user ID\n",
    "# user_profile = create_user_profile(user_id, merged_df, tfidf_matrix)\n",
    "# recommended_movies = recommend(user_profile, tfidf_matrix, merged_df, user_id)\n",
    "# print(\"Recommended movies for user {}: {}\".format(user_id, recommended_movies))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
